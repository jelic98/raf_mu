ODGOVOR 1A
Razlika između K-fold i Leave one out: Leave one out je specijalan slučaj K-fold algoritma u kome se model testira na jednom objektu, dok se za treniranje koriste svi ostali. Konkretno, za Leave one out algoritam K ima vrednost N, gde je N ukupna broj objekata.
Razlika između K-fold i Random subsampling: Kod Random subsampling algoritma ne dolazi do mešanja skupova za treniranje i testiranje, dok se kod K-fold algoritma jedan podskup objekata koristi kao skup za treniranje K-1 puta, a kao skup za testiranje tačno jednom.
Razlika između Leave one out i Random subsampling: Kod Leave one out algoritma model se testira na svakom objektu, dok se kod Random subsampling algoritma model testira samo na jednom podskupu objekata.

ODGOVOR 1B
Gaussian Naive Bayes: Obeležja po kojima se klasifikuju objekti su binarne prirode, tj. vrednost odeležja može biti TRUE ili FALSE.
Multinomial Naive Bayes: Obeležja po kojima se klasifikuju objekti su diskretne prirode, tj. vrednost odeležja može biti ceo broj koji predstavlja frekvenciju pojavljivanja objekta sa tim obeležjem.
Bernoulli Naive Bayes: Obeležja po kojima se klasifikuju objekti su kontinualne prirode, tj. vrednost odeležja može biti realan broj iz normalne raspodele obeležja po svim objektima.

ODGOVOR 1C
Linear separability: Dva skupa su linearno separabilna, ako postoji prava koja deli dve klase objekata tako što se objekti prve i druge klase nalaze sa suprotnih strana te prave. Objekti iz skupa iris.csv su linearno separabilni zato što postoji beskonačno mnogo pravih koje razdvajaju objekte klase Setosa od unije objekata klasa Versicolor i Virginica.

ODGOVOR 2A
Pored toga što se vrednost funkcije troška smanjuje povećanjem stepena polinoma koji opisuje ulazne podatke, možemo primetiti izuzetke kod polinoma petog i šestog stepena. To je zato što usled nasumičnog mešanja skupa ulaznih podataka funkcija koja optimalno opisuje te podatke i funkcija u obliku polinoma visokog stepena prilaze asimptotama sa suprotnih strana.

ODGOVOR 2B
Očigledno je da se sa povećanjem vrednosti lambda parametra, povećava i vrednost funkcije greške zato što u tom slučaju sabirak za L2 regularizaciju imati značajno veću vrednost, tj. kompleksnost modela će više uticati na povećanje vrednosti funkcije troška.

ODGOVOR 3B
Optimalna vrednost parametra K zavisi od načina na koji je skup podataka podeljen, tj. koji se podaci nalaze u skupu za treniranje, a koji u skupu za testiranje. Na osnovu višestrukog testiranja, može se zaključiti da je vrednost jedna od boljih vrednost za parametar K baš ceo broj iz intervala [3, 7] i može se odabrati broj 5 kao medijana. Mala vrednost parametra K navodi model da ne gleda širu sliku, dok se korišćenjem veća vrednosti mogu uzeti u obzir i objekti klasa koja nije ciljna.

ODGOVOR 3C
Na grafiku se može videti horizontalna linija koja pokazuje da je tačnost modela 100%, nezavisno od vrednosti parametra K. Ovo pojava se dešava kada su klase dobro grupisane. Ipak, tvrđenje iz prethodog dela zadatka ostaje da važi zato što bi se povećanjem vrednosti parametra K u jednom trenutku primetilo opadanje tačnosti modela zato što bi veličina klase bila manja od broja susednih objekata koje uzimamo u obzir pri određivanju klase objekta iz skupa podataka za testiranje.

ODGOVOR 4C
Posmatrajući skup reči koje se najčešće pojavljuju u pozitivnim i skup reči koje se najčešće pojavljuju u negativnim tvitovima, možemo primetiti da presek ta dva skupa nije prazan, tj. postoje reči koje se inače često upotrebljavju. Kako bi se stekao uvid u realnu situaciju (skup reči koje su jako vezane za sentiment tvita), može se koristiti LR metrika (likelihood ratio) koja relativizuje frekvencije pojavljivanja reči.
